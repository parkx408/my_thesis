\section{Independent Component Analysis}
\label{BG_ICA}
While the PB method quantifies effect of each input parameters to output of interest, it does have one major drawback. 
Because the effect estimation assumes any higher order effects to be zero, the estimated effects of any main factor is partially aliased with any interactions not including that particular main factor. 

In contrast, \emph{Principal Component Analysis} (PCA) and \emph{Independent Component Analysis} (ICA) estimate the effect of uncorrelated components of original factors~\cite{stone:2002}. 
These components may not reflect any intuitively meaningful parameter. 
However, they do provide a uncorrelated set of factors that can be derived from the original ones. 
The limitation of the PCA is that it requires the original factors to be normally distributed. 
ICA is a more generic approach in that such assumption is not required~\cite{christopoulos:2008}. 
It has been observed that ICA performs better than PCA in capturing processor workload space~\cite{eeckhout:2005}. 

In essence, ICA tries to identify statistically independent components from given factors. 

Formally, ICA estimates a matrix $\mathbf{W}$ such that given $\mathbf{x}=(x_1, x_2, ..., x_n)$ with joint \emph{probability density function} (pdf) $p_x(x_1, x_2, ..., x_n)$ such that $\mathbf{y}=\mathbf{W} \times \mathbf{x}$ has joint pdf $p_y(\mathbf{y}$ with following property.
\begin{equation}\label{independence}
E[y_1^{p_1}, y_2^{p_2}, ..., y_m^{p_m}]=E[y_1^{p_1}]E[y_2^{p_2}]...E[y_m^{p_m}]
\end{equation}
for every integer value of $p_i$ and $m \le n$. Equation \ref{independence} is the definition of independence.
