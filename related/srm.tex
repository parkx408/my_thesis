%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% srm.tex: Storage Consolidation and Resource Management.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Storage Consolidation and Resource Management}
\label{bg_srm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Our experiments have revealed that storage workload and storage device
models are highly inter-dependent.
This confirms observations from other works~\cite{wang:2004, park:2011}.

Early efforts to automatically manage storage resources in a
virtualized environment such as \emph{VectorDot}~\cite{singh:2008}
ignored the workload and simply concentrated on utilization of each
storage system. A workload from the over-loaded device is simply
migrated to a less loaded device. This approach would fail to
work in a heterogeneous storage environment since the resulting
performance is unknown. Furthermore, the goal is not to simply ensure
that no storage system suffers from over-utilization but to minimize the performance degradation caused by resource sharing across all workloads.

Other work has focused on highly accurate latency prediction of
workloads across storage devices but this has come at the cost of
practicality by requiring extensive off-line experimentation and
modeling. For instance, Wang et al.~\cite{wang:2004} developed
CART models off-line to develop workload-storage models. In contrast
to their work, \romano aims to be learn storage behavior quickly using
online calibration without resorting to intrusive off-line methods.

Earlier work in this area include Basil~\cite{gulati:2010} and
Pesto~\cite{gulati:2011} which propose creating separate workload and device
models and using heuristics to perform load balancing. The underlying
assumption is the independence of the two classes of models. A
commercial product~\cite{vmware:2006} based on Pesto is now
available. Whereas Basil and Pesto have very good average behavior,
they suffer from severe corner case model inaccuracies. For example,
it was shown in their work that the prediction error can be more than
10 times larger than the latency it predicts for sequential workloads.
These can lead to bad data movement recommendations. To address these
shortcomings, Pesto applies aggressive cost-benefit analysis to prune
out potentially bad moves. The inadvertent result of this pruning to
deal with model inaccuracies is that many highly beneficial moves are
also left out.

\romano proposes to deal with these problems by creating a model
capable of determining its own confidence of prediction using
\emph{prediction interval}~\cite{chatfield:1993}.
Furthermore, Romano is capable of quantifying the effect of the
workload characteristics and their interactions for a given data store
resulting in much more accurate and robust modeling.
